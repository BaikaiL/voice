{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaikaiL/voice/blob/main/translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngeC9T8WhbC4",
        "outputId": "ec8b554b-b8ba-4d91-fa16-c496ad35eaef",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: edge-tts in /usr/local/lib/python3.12/dist-packages (7.2.7)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from edge-tts) (3.13.2)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.12/dist-packages (from edge-tts) (2025.11.12)\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from edge-tts) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.0->edge-tts) (3.11)\n"
          ]
        }
      ],
      "source": [
        "# å®‰è£… Edge-TTS (ç”¨äºé«˜è´¨é‡è¯­éŸ³åˆæˆ)\n",
        "!pip install edge-tts nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å¾®è°ƒæ¨¡å‹åŠ è½½\n",
        "import torch\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import edge_tts\n",
        "from transformers import pipeline, AutoProcessor, AutoModelForSpeechSeq2Seq # å¼•å…¥æ›´åº•å±‚çš„ç±»\n",
        "import IPython.display as ipd\n",
        "import uuid\n",
        "import gradio as gr\n",
        "\n",
        "# è§£å†³ Jupyter/Colab ä¸­çš„å¼‚æ­¥å¾ªç¯å†²çªé—®é¢˜\n",
        "nest_asyncio.apply()\n",
        "\n",
        "class CantonesToMandarinTranslator:\n",
        "    def __init__(self):\n",
        "        # è‡ªåŠ¨æ£€æµ‹ GPU\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "        print(f\"æ­£åœ¨åˆå§‹åŒ–... (Device: {self.device})\")\n",
        "\n",
        "        # ä¸€. åŠ è½½ ASR æ¨¡å‹\n",
        "        print(\"æ­£åœ¨åŠ è½½ Whisper (ASR)...\")\n",
        "\n",
        "        # 1. ä»ä»“åº“åŠ è½½å¾®è°ƒåçš„æ¨¡å‹æƒé‡\n",
        "        my_model_id = \"baikai1022/whisper-small-cantonese-v2\"\n",
        "        model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "            my_model_id,\n",
        "            torch_dtype=self.torch_dtype,\n",
        "            low_cpu_mem_usage=True,\n",
        "            use_safetensors=True\n",
        "        ).to(self.device)\n",
        "\n",
        "        # 2. ä» OpenAI åŸç‰ˆåŠ è½½å¤„ç†å™¨/åˆ†è¯å™¨ (å¡«è¡¥ä»“åº“ç¼ºå¤±çš„æ–‡ä»¶)\n",
        "        processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "        # 3. æ‰‹åŠ¨ç»„è£… Pipeline\n",
        "        self.asr_pipe = pipeline(\n",
        "            \"automatic-speech-recognition\",\n",
        "            model=model,\n",
        "            tokenizer=processor.tokenizer,           # å€Ÿç”¨åŸç‰ˆ tokenizer\n",
        "            feature_extractor=processor.feature_extractor, # å€Ÿç”¨åŸç‰ˆ feature_extractor\n",
        "            device=self.device,\n",
        "            torch_dtype=self.torch_dtype,\n",
        "        )\n",
        "\n",
        "         # äºŒ. åŠ è½½ NLLB æ¨¡å‹ (Translation)\n",
        "        print(\"æ­£åœ¨åŠ è½½ NLLB (Translation)...\")\n",
        "        self.mt_pipe = pipeline(\n",
        "            \"translation\",\n",
        "            model=\"baikai1022/nllb-cantonese-mandarin-v1\",\n",
        "            device=self.device,\n",
        "            torch_dtype=self.torch_dtype,\n",
        "            src_lang=\"yue_Hant\",\n",
        "            tgt_lang=\"zho_Hans\"\n",
        "        )\n",
        "        print(\"æ¨¡å‹åŠ è½½å®Œæˆï¼\")\n",
        "\n",
        "    def run(self, audio_path, output_audio_path=\"output_mandarin.mp3\"):\n",
        "        print(\"\\n\" + \"=\"*40)\n",
        "        print(f\"å¤„ç†éŸ³é¢‘: {audio_path}\")\n",
        "\n",
        "        # --- æ­¥éª¤ 1: è¯­éŸ³è¯†åˆ« ---\n",
        "        asr_result = self.asr_pipe(\n",
        "            audio_path,\n",
        "        )\n",
        "        cantonese_text = asr_result[\"text\"]\n",
        "        print(f\"[è¯†åˆ«ç»“æœ (ç²¤è¯­)]: {cantonese_text}\")\n",
        "\n",
        "        # --- æ­¥éª¤ 2: æœºå™¨ç¿»è¯‘ ---\n",
        "        mt_result = self.mt_pipe(cantonese_text)\n",
        "        mandarin_text = mt_result[0]['translation_text']\n",
        "        print(f\"[ç¿»è¯‘ç»“æœ (å›½è¯­)]: {mandarin_text}\")\n",
        "\n",
        "        # --- æ­¥éª¤ 3: è¯­éŸ³åˆæˆ ---\n",
        "        print(\"æ­£åœ¨åˆæˆè¯­éŸ³...\")\n",
        "        voice = \"zh-CN-XiaoxiaoNeural\"\n",
        "\n",
        "        async def _generate_tts():\n",
        "            communicate = edge_tts.Communicate(mandarin_text, voice)\n",
        "            await communicate.save(output_audio_path)\n",
        "\n",
        "        asyncio.run(_generate_tts())\n",
        "\n",
        "        print(f\"åˆæˆå®Œæˆ: {output_audio_path}\")\n",
        "        print(\"=\"*40 + \"\\n\")\n",
        "        return output_audio_path, mandarin_text\n",
        "\n",
        "    def process(self, audio_path):\n",
        "        \"\"\"\n",
        "        ä¸“é—¨ç»™ Gradio ç”¨çš„å¤„ç†å‡½æ•°\n",
        "        è¿”å›: (ç²¤è¯­æ–‡æœ¬, æ™®é€šè¯æ–‡æœ¬, æ™®é€šè¯éŸ³é¢‘è·¯å¾„)\n",
        "        \"\"\"\n",
        "        if not audio_path:\n",
        "            return \"è¯·å…ˆå½•éŸ³æˆ–ä¸Šä¼ æ–‡ä»¶\", \"\", None\n",
        "\n",
        "        print(f\"æ­£åœ¨å¤„ç†: {audio_path}\")\n",
        "\n",
        "        # 1. ASR è¯†åˆ«\n",
        "        # æŒ‡å®š language=\"chinese\" ä»¥åˆ©ç”¨å¾®è°ƒæ•ˆæœä¸”é¿å…æŠ¥é”™\n",
        "        asr_result = self.asr_pipe(audio_path)\n",
        "        cantonese_text = asr_result[\"text\"]\n",
        "\n",
        "        # 2. MT ç¿»è¯‘\n",
        "        mt_result = self.mt_pipe(cantonese_text)\n",
        "        mandarin_text = mt_result[0]['translation_text']\n",
        "\n",
        "        # 3. TTS åˆæˆ\n",
        "        # ä½¿ç”¨éšæœºæ–‡ä»¶åï¼Œé˜²æ­¢å¤šäººä½¿ç”¨æ—¶å†²çª\n",
        "        output_filename = f\"out_{uuid.uuid4().hex[:8]}.mp3\"\n",
        "        voice = \"zh-CN-XiaoxiaoNeural\"\n",
        "\n",
        "        async def _gen_tts():\n",
        "            comm = edge_tts.Communicate(mandarin_text, voice)\n",
        "            await comm.save(output_filename)\n",
        "\n",
        "        asyncio.run(_gen_tts())\n",
        "\n",
        "        return cantonese_text, mandarin_text, output_filename\n",
        "\n",
        "# è¿è¡Œæµ‹è¯•\n",
        "translator = CantonesToMandarinTranslator()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPo_fjCZhxDR",
        "outputId": "5a9b9de2-721b-4551-f7f1-84126aa080a9",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨åˆå§‹åŒ–... (Device: cuda)\n",
            "æ­£åœ¨åŠ è½½ Whisper (ASR)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Device set to use cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨åŠ è½½ NLLB (Translation)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ¨¡å‹åŠ è½½å®Œæˆï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# åŸç‰ˆæ¨¡å‹åŠ è½½\n",
        "class OriginalTranslator:\n",
        "    def __init__(self):\n",
        "        # è‡ªåŠ¨æ£€æµ‹ GPU\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "        print(f\"æ­£åœ¨åˆå§‹åŒ–åŸç‰ˆæ¨¡å‹... (Device: {self.device})\")\n",
        "\n",
        "        # 1. åŠ è½½åŸç‰ˆ Whisper (openai/whisper-small)\n",
        "        print(\"æ­£åœ¨åŠ è½½åŸç‰ˆ Whisper (Base)...\")\n",
        "        self.asr_pipe = pipeline(\n",
        "            \"automatic-speech-recognition\",\n",
        "            model=\"openai/whisper-small\", # ä½¿ç”¨å®˜æ–¹åŸç‰ˆæƒé‡\n",
        "            device=self.device,\n",
        "            torch_dtype=self.torch_dtype,\n",
        "        )\n",
        "\n",
        "        # 2. åŠ è½½åŸç‰ˆ NLLB (facebook/nllb-200-distilled-600M)\n",
        "        # æ³¨æ„ï¼šä½ çš„å¾®è°ƒç‰ˆé€šå¸¸æ˜¯åŸºäº distilled-600M ç‰ˆæœ¬å¾®è°ƒçš„\n",
        "        print(\"æ­£åœ¨åŠ è½½åŸç‰ˆ NLLB (Base)...\")\n",
        "        self.mt_pipe = pipeline(\n",
        "            \"translation\",\n",
        "            model=\"facebook/nllb-200-distilled-600M\", # ä½¿ç”¨å®˜æ–¹åŸç‰ˆæƒé‡\n",
        "            device=self.device,\n",
        "            torch_dtype=self.torch_dtype,\n",
        "            src_lang=\"yue_Hant\",\n",
        "            tgt_lang=\"zho_Hans\"\n",
        "        )\n",
        "        print(\"åŸç‰ˆæ¨¡å‹åŠ è½½å®Œæˆï¼\")\n",
        "\n",
        "    def process(self, audio_path):\n",
        "        if not audio_path:\n",
        "            return \"æ— è¾“å…¥\", \"æ— è¾“å…¥\"\n",
        "\n",
        "        # 1. åŸç‰ˆ ASR è¯†åˆ«\n",
        "        # å¼ºåˆ¶æŒ‡å®šè¯­è¨€ä¸º chinese å¦åˆ™åŸç‰ˆç»å¸¸ä¼šè¯†åˆ«æˆè‹±æ–‡\n",
        "        asr_result = self.asr_pipe(audio_path, generate_kwargs={\"language\": \"chinese\", \"task\": \"transcribe\"})\n",
        "        cantonese_text = asr_result[\"text\"]\n",
        "\n",
        "        # 2. åŸç‰ˆ MT ç¿»è¯‘\n",
        "        mt_result = self.mt_pipe(cantonese_text)\n",
        "        mandarin_text = mt_result[0]['translation_text']\n",
        "\n",
        "        return cantonese_text, mandarin_text\n",
        "\n",
        "# åˆå§‹åŒ–åŸç‰ˆ\n",
        "original_translator = OriginalTranslator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teWHloAUzSd5",
        "outputId": "41dae0d5-cb3d-4e44-861c-02a69edf0511"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨åˆå§‹åŒ–åŸç‰ˆæ¨¡å‹... (Device: cuda)\n",
            "æ­£åœ¨åŠ è½½åŸç‰ˆ Whisper (Base)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨åŠ è½½åŸç‰ˆ NLLB (Base)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "åŸç‰ˆæ¨¡å‹åŠ è½½å®Œæˆï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å¾®è°ƒæ¨¡å‹æµ‹è¯•\n",
        "# è¯·ç¡®ä¿è¿™é‡Œæœ‰æ–‡ä»¶ï¼Œæˆ–è€…ä¿®æ”¹æ–‡ä»¶å\n",
        "input_audio = \"common_voice_zh-HK_20110217.wav\"\n",
        "\n",
        "import os\n",
        "if os.path.exists(input_audio):\n",
        "    output, text = translator.run(input_audio)\n",
        "    ipd.display(ipd.Audio(output))\n",
        "else:\n",
        "    print(f\"è¯·ä¸Šä¼ ä¸€ä¸ªåä¸º {input_audio} çš„ç²¤è¯­å½•éŸ³æ–‡ä»¶æ¥æµ‹è¯•\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcJqS5BkjFXx",
        "outputId": "fc3781d6-8708-4694-957f-dacfd5a58ee2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¯·ä¸Šä¼ ä¸€ä¸ªåä¸º common_voice_zh-HK_20110217.wav çš„ç²¤è¯­å½•éŸ³æ–‡ä»¶æ¥æµ‹è¯•\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# åˆ›å»ºç›®å½•å­˜æ”¾ç¿»è¯‘åçš„å¯¹æ¯”éŸ³é¢‘\n",
        "import os\n",
        "import glob\n",
        "import asyncio\n",
        "import edge_tts\n",
        "\n",
        "# åˆ›å»ºå­˜æ”¾ç»“æœçš„æ–‡ä»¶å¤¹\n",
        "os.makedirs(\"output_ft\", exist_ok=True)    # å­˜æ”¾å¾®è°ƒæ¨¡å‹ (Fine-tuned) çš„éŸ³é¢‘\n",
        "os.makedirs(\"output_base\", exist_ok=True)  # å­˜æ”¾åŸç‰ˆæ¨¡å‹ (Base) çš„éŸ³é¢‘\n",
        "\n",
        "print(\"æ–‡ä»¶å¤¹å‡†å¤‡å°±ç»ªï¼šoutput_ft/ å’Œ output_base/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6XszPWs03dB",
        "outputId": "d8161e94-28de-43d3-d8c2-fb930aab2ec5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ–‡ä»¶å¤¹å‡†å¤‡å°±ç»ªï¼šoutput_ft/ å’Œ output_base/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def generate_tts_async(text, output_path):\n",
        "    \"\"\"å¼‚æ­¥åˆæˆè¯­éŸ³å¹¶ä¿å­˜\"\"\"\n",
        "    voice = \"zh-CN-XiaoxiaoNeural\"\n",
        "    communicate = edge_tts.Communicate(text, voice)\n",
        "    await communicate.save(output_path)\n",
        "\n",
        "def save_tts(text, output_path):\n",
        "    \"\"\"åŒæ­¥è°ƒç”¨å¼‚æ­¥ TTS\"\"\"\n",
        "    if text.strip():\n",
        "        asyncio.run(generate_tts_async(text, output_path))\n",
        "    else:\n",
        "        print(f\"è­¦å‘Šï¼šæ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡ TTS åˆæˆ {output_path}\")"
      ],
      "metadata": {
        "id": "Lib50UEy0-NP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æ¨¡å‹å¾®è°ƒå‰åå¯¹æ¯”\n",
        "# 1. è·å–æ‰€æœ‰å¾…æµ‹è¯•çš„ wav æ–‡ä»¶\n",
        "test_files = glob.glob(\"*.wav\")\n",
        "\n",
        "if not test_files:\n",
        "    print(\"å½“å‰ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° .wav æ–‡ä»¶ï¼Œè¯·ä¸Šä¼ åå†æµ‹è¯•ã€‚\")\n",
        "else:\n",
        "    print(f\"æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œå¼€å§‹å¯¹æ¯”å¤„ç†...\\n\")\n",
        "\n",
        "    for audio_file in test_files:\n",
        "        print(f\"æ­£åœ¨å¤„ç†: {audio_file}\")\n",
        "        file_name = os.path.splitext(audio_file)[0] # è·å–ä¸å¸¦åç¼€çš„æ–‡ä»¶å\n",
        "\n",
        "        # --- A. ä½¿ç”¨å¾®è°ƒæ¨¡å‹ (translator) ---\n",
        "        try:\n",
        "            # è°ƒç”¨ä½ åŸæœ¬ç±»ä¸­çš„ process æ–¹æ³•\n",
        "            ft_cantonese, ft_mandarin, _ = translator.process(audio_file)\n",
        "            ft_audio_path = f\"output_ft/{file_name}_ft.mp3\"\n",
        "            save_tts(ft_mandarin, ft_audio_path)\n",
        "            print(f\"  [å¾®è°ƒç‰ˆ] ç¿»è¯‘: {ft_mandarin}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  [å¾®è°ƒç‰ˆ] æŠ¥é”™: {e}\")\n",
        "\n",
        "        # --- B. ä½¿ç”¨åŸç‰ˆæ¨¡å‹ (original_translator) ---\n",
        "        try:\n",
        "            # è°ƒç”¨åŸç‰ˆç±»çš„ process æ–¹æ³• (å‡è®¾ä½ å·²ç»å®šä¹‰äº† original_translator)\n",
        "            base_cantonese, base_mandarin = original_translator.process(audio_file)\n",
        "            base_audio_path = f\"output_base/{file_name}_base.mp3\"\n",
        "            save_tts(base_mandarin, base_audio_path)\n",
        "            print(f\"  [åŸç‰ˆ]   ç¿»è¯‘: {base_mandarin}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  [åŸç‰ˆ]   æŠ¥é”™: {e}\")\n",
        "\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    print(\"\\nâœ… æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆï¼\")\n",
        "    print(\"å¾®è°ƒéŸ³é¢‘ä¿å­˜åœ¨: output_ft/\")\n",
        "    print(\"åŸç‰ˆéŸ³é¢‘ä¿å­˜åœ¨: output_base/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDUGZiIv1ELQ",
        "outputId": "d1de5b57-0b4d-464d-c483-dad672625fd7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ‰¾åˆ° 5 ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œå¼€å§‹å¯¹æ¯”å¤„ç†...\n",
            "\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20136999.wav\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20136999.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
            "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
            "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n",
            "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
            "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
            "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [å¾®è°ƒç‰ˆ] ç¿»è¯‘: æµæµªçŒ«åœ¨æ²™ç”°å’Œåœ£è¡—çš„åƒåœ¾æ¡¶é¥®é£Ÿã€‚\n",
            "  [åŸç‰ˆ]   ç¿»è¯‘: æµæµªçŒ«åœ¨æ²™æ¼ å’Œè¡—å¤´åƒåœ¾æ¡¶é‡Œå¯»æ‰¾é£Ÿç‰©.\n",
            "------------------------------\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20110217.wav\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20110217.wav\n",
            "  [å¾®è°ƒç‰ˆ] ç¿»è¯‘: æœ‰ä¸ªè€å©†å©†åœ¨å¤§åŸ”æ•™è”è·¯ç­‰å°å·´ã€‚\n",
            "  [åŸç‰ˆ]   ç¿»è¯‘: ä¸€ä½è€å©†åœ¨æµ¦ç­‰ç€å·´å£«.\n",
            "------------------------------\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20137068.wav\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20137068.wav\n",
            "  [å¾®è°ƒç‰ˆ] ç¿»è¯‘: å¾ˆä¹…æ²¡å»è§‚å…¬è½é“æ¢å£åºœã€‚\n",
            "  [åŸç‰ˆ]   ç¿»è¯‘: å¾ˆä¹…ä»¥å‰,æˆ‘è¿˜æ²¡æœ‰å»çœ‹.\n",
            "------------------------------\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20110228.wav\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20110228.wav\n",
            "  [å¾®è°ƒç‰ˆ] ç¿»è¯‘: ç“¦å·´ç”¸æ–°é“\n",
            "  [åŸç‰ˆ]   ç¿»è¯‘: å·´çš„èº«ä½“çŠ¶å†µ\n",
            "------------------------------\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20110241.wav\n",
            "æ­£åœ¨å¤„ç†: common_voice_zh-HK_20110241.wav\n",
            "  [å¾®è°ƒç‰ˆ] ç¿»è¯‘: æ¯”æˆ‘ä¸€ä¸ªäººé™ä¸‹è¡Œä¸è¡Œã€‚\n",
            "  [åŸç‰ˆ]   ç¿»è¯‘: è®©æˆ‘ä¸€ä¸ªäººèµ°ä¸€è·¯.\n",
            "------------------------------\n",
            "\n",
            "âœ… æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆï¼\n",
            "å¾®è°ƒéŸ³é¢‘ä¿å­˜åœ¨: output_ft/\n",
            "åŸç‰ˆéŸ³é¢‘ä¿å­˜åœ¨: output_base/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UIç•Œé¢äº¤äº’ï¼ˆåŸç‰ˆï¼‰\n",
        "def gradio_interface(audio):\n",
        "    return translator.process(audio)\n",
        "\n",
        "with gr.Blocks(title=\"ç²¤è¯­è½¬æ™®é€šè¯ AI\") as demo:\n",
        "    gr.Markdown(\"# ğŸ‡­ğŸ‡° ç²¤è¯­ -> ğŸ‡¨ğŸ‡³ æ™®é€šè¯ æ™ºèƒ½è½¬æ¢å™¨\")\n",
        "    gr.Markdown(\"åŸºäº Whisper-Small (å¾®è°ƒ) + NLLB-200 (å¾®è°ƒ) + Edge-TTS\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # å·¦ä¾§ï¼šè¾“å…¥åŒº\n",
        "        with gr.Column():\n",
        "            # sources=[\"microphone\"] å…è®¸å½•éŸ³ï¼Œtype=\"filepath\" ä¼ é€’æ–‡ä»¶è·¯å¾„\n",
        "            input_audio = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"è¯·è¯´ç²¤è¯­\")\n",
        "            btn = gr.Button(\"å¼€å§‹è½¬æ¢\", variant=\"primary\")\n",
        "\n",
        "        # å³ä¾§ï¼šè¾“å‡ºåŒº\n",
        "        with gr.Column():\n",
        "            txt_cantonese = gr.Textbox(label=\"è¯†åˆ«ç»“æœ (ç²¤è¯­)\")\n",
        "            txt_mandarin = gr.Textbox(label=\"ç¿»è¯‘ç»“æœ (æ™®é€šè¯)\")\n",
        "            out_audio = gr.Audio(label=\"åˆæˆè¯­éŸ³ (æ™®é€šè¯)\", autoplay=True)\n",
        "\n",
        "    # ç»‘å®šç‚¹å‡»äº‹ä»¶\n",
        "    btn.click(\n",
        "        fn=gradio_interface,\n",
        "        inputs=input_audio,\n",
        "        outputs=[txt_cantonese, txt_mandarin, out_audio]\n",
        "    )\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "_8KvQyCKmo3g",
        "outputId": "688bb359-3002-4af0-a65c-5035e48bf21f",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gr' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-371529302.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ç²¤è¯­è½¬æ™®é€šè¯ AI\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# ğŸ‡­ğŸ‡° ç²¤è¯­ -> ğŸ‡¨ğŸ‡³ æ™®é€šè¯ æ™ºèƒ½è½¬æ¢å™¨\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"åŸºäº Whisper-Small (å¾®è°ƒ) + NLLB-200 (å¾®è°ƒ) + Edge-TTS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyecharts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L7WjmaS3uR5",
        "outputId": "fe42cd56-a37b-4439-b1f7-81b60c106cf4",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyecharts\n",
            "  Downloading pyecharts-2.0.9-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from pyecharts) (3.1.6)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from pyecharts) (3.17.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from pyecharts) (3.20.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->pyecharts) (3.0.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->pyecharts) (0.2.14)\n",
            "Downloading pyecharts-2.0.9-py3-none-any.whl (153 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/153.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyecharts\n",
            "Successfully installed pyecharts-2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjjbMbBu4po4",
        "outputId": "4b175ccf-2e10-4c6a-89e7-871083364ea9",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æ€§èƒ½å¯è§†åŒ–UIäº¤äº’ç•Œé¢ï¼ˆç¬¬ä¸€ç‰ˆï¼‰\n",
        "import gradio as gr\n",
        "import psutil\n",
        "import torch\n",
        "import plotly.graph_objects as go  # å¯¼å…¥ Plotly\n",
        "\n",
        "# --- 1. åˆ›å»º Plotly ç»˜å›¾å‡½æ•° ---\n",
        "def create_perf_plot(ram_value, vram_value):\n",
        "    # åˆ›å»ºä¸€ä¸ªäº¤äº’å¼æŸ±çŠ¶å›¾\n",
        "    fig = go.Figure(data=[\n",
        "        go.Bar(\n",
        "            x=[\"ç³»ç»Ÿå†…å­˜ (RAM)\", \"æ˜¾å­˜å³°å€¼ (VRAM)\"],\n",
        "            y=[round(ram_value, 2), round(vram_value, 2)],\n",
        "            marker_color=['#636EFA', '#EF553B'], # è®¾ç½®è“è‰²å’Œçº¢è‰²\n",
        "            text=[f\"{ram_value:.2f} GB\", f\"{vram_value:.2f} GB\"], # æŸ±å­ä¸Šæ˜¾ç¤ºçš„æ–‡å­—\n",
        "            textposition='auto',\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"ç¡¬ä»¶èµ„æºå ç”¨ç»Ÿè®¡ (å•ä½: GB)\",\n",
        "        yaxis=dict(range=[0, 16]), # æ ¹æ® Colab å¸¸è§å†…å­˜ä¸Šé™è®¾ç½®åæ ‡è½´èŒƒå›´\n",
        "        height=300,\n",
        "        margin=dict(l=20, r=20, t=40, b=20),\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\", # é€æ˜èƒŒæ™¯\n",
        "        plot_bgcolor=\"rgba(0,0,0,0)\"\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "# --- 2. æ¥å£å‡½æ•° ---\n",
        "def gradio_interface(audio):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    # æ‰§è¡Œä½ åŸæœ¬çš„ç¿»è¯‘é€»è¾‘\n",
        "    # å‡è®¾ translator.process è¿”å›: ç²¤è¯­æ–‡æœ¬, æ™®é€šè¯æ–‡æœ¬, éŸ³é¢‘\n",
        "    cantonese_res, mandarin_res, audio_res = translator.process(audio)\n",
        "\n",
        "    # è·å–èµ„æºæ•°æ®\n",
        "    ram = psutil.virtual_memory().used / (1024**3)\n",
        "    vram = 0\n",
        "    if torch.cuda.is_available():\n",
        "        vram = torch.cuda.max_memory_allocated() / (1024**3)\n",
        "\n",
        "    # ç”Ÿæˆ Plotly å›¾è¡¨å¯¹è±¡\n",
        "    fig = create_perf_plot(ram, vram)\n",
        "\n",
        "    return cantonese_res, mandarin_res, audio_res, fig\n",
        "\n",
        "# --- 3. æ„å»º UI ç•Œé¢ ---\n",
        "with gr.Blocks(title=\"ç²¤è¯­è½¬æ™®é€šè¯ AI\") as demo:\n",
        "    gr.Markdown(\"# ğŸ‡­ğŸ‡° ç²¤è¯­ -> ğŸ‡¨ğŸ‡³ æ™®é€šè¯ æ™ºèƒ½è½¬æ¢å™¨\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # å·¦ä¾§è¾“å…¥\n",
        "        with gr.Column():\n",
        "            input_audio = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"è¯·è¯´ç²¤è¯­\")\n",
        "            btn = gr.Button(\"ğŸš€ å¼€å§‹è½¬æ¢\", variant=\"primary\")\n",
        "\n",
        "            # --- é‡è¦ï¼šä½¿ç”¨ gr.Plot ä¸“é—¨æ˜¾ç¤ºäº¤äº’å¼å›¾è¡¨ ---\n",
        "            perf_plot = gr.Plot(label=\"èµ„æºå ç”¨ç›‘æ§\")\n",
        "\n",
        "        # å³ä¾§è¾“å‡º\n",
        "        with gr.Column():\n",
        "            txt_cantonese = gr.Textbox(label=\"è¯†åˆ«ç»“æœ (ç²¤è¯­)\")\n",
        "            txt_mandarin = gr.Textbox(label=\"ç¿»è¯‘ç»“æœ (æ™®é€šè¯)\")\n",
        "            out_audio = gr.Audio(label=\"åˆæˆè¯­éŸ³ (æ™®é€šè¯)\", autoplay=True)\n",
        "\n",
        "    # ç»‘å®šäº‹ä»¶\n",
        "    btn.click(\n",
        "        fn=gradio_interface,\n",
        "        inputs=input_audio,\n",
        "        outputs=[txt_cantonese, txt_mandarin, out_audio, perf_plot]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "KiEoXoZG30eR",
        "outputId": "7ce5d255-61c6-4116-e6da-58e4bb9e2dbf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://f10f3a5454acd90d56.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f10f3a5454acd90d56.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨å¤„ç†: /tmp/gradio/3489f36f5fe91be962bf7dd6e3d17b1d1e3678a1fc3038ff85702bff7fb7a7e4/audio.wav\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://f10f3a5454acd90d56.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gradio plotly pandas\n",
        "# è¿è¡Œåå¦‚æœæç¤º \"Restart Session\"ï¼Œè¯·ç‚¹å‡»æŒ‰é’®é‡å¯ï¼Œå¦åˆ™ä»£ç ä¼šæŠ¥é”™ã€‚"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "o18BroIE5c3f",
        "outputId": "e1ecfabc-9542-407d-99ae-c8844fe37d83"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-6.3.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Collecting plotly\n",
            "  Downloading plotly-6.5.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Collecting gradio-client==2.0.3 (from gradio)\n",
            "  Downloading gradio_client-2.0.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<13.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==2.0.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from plotly) (2.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-6.3.0-py3-none-any.whl (23.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-2.0.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-6.5.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: plotly, pandas, gradio-client, gradio\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.14.0\n",
            "    Uninstalling gradio_client-1.14.0:\n",
            "      Successfully uninstalled gradio_client-1.14.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.50.0\n",
            "    Uninstalling gradio-5.50.0:\n",
            "      Successfully uninstalled gradio-5.50.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gradio-6.3.0 gradio-client-2.0.3 pandas-2.3.3 plotly-6.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gradio",
                  "pandas"
                ]
              },
              "id": "57a2facce07a41b6b04e2f8a2869e65b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æ€§èƒ½å¯è§†åŒ–UIäº¤äº’ç•Œé¢ï¼ˆç¬¬äºŒç‰ˆï¼‰\n",
        "import gradio as gr\n",
        "import psutil\n",
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "\n",
        "# --- 1. ç›‘æ§æ•°æ®ä¸ç»˜å›¾é€»è¾‘ ---\n",
        "def get_perf_figure(history_df):\n",
        "    \"\"\"æ ¹æ®æ•°æ®ç”Ÿæˆ Plotly å›¾è¡¨\"\"\"\n",
        "    if history_df.empty:\n",
        "        # åˆå§‹ç©ºå›¾è¡¨ï¼Œé˜²æ­¢ç™½å±\n",
        "        fig = px.line(title=\"æ€§èƒ½ç›‘æ§å¯åŠ¨ä¸­...\")\n",
        "    else:\n",
        "        fig = px.line(\n",
        "            history_df, x=\"Time\", y=\"Value\", color=\"Type\",\n",
        "            title=\"å®æ—¶æ€§èƒ½ç›‘æ§ (ç§’çº§æ›´æ–°)\",\n",
        "            range_y=[0, 8],\n",
        "            template=\"plotly_white\"\n",
        "        )\n",
        "    fig.update_layout(height=300, margin=dict(l=10, r=10, t=40, b=10))\n",
        "    return fig\n",
        "\n",
        "# å­˜å‚¨å†å²æ•°æ®\n",
        "if 'perf_history' not in globals():\n",
        "    perf_history = pd.DataFrame(columns=[\"Time\", \"Value\", \"Type\"])\n",
        "\n",
        "def update_monitor_plot():\n",
        "    global perf_history\n",
        "    now = datetime.now().strftime(\"%H:%M:%S\")\n",
        "\n",
        "    # é‡‡é›†æ•°æ®\n",
        "    ram = psutil.virtual_memory().used / (1024**3)\n",
        "    vram = 0\n",
        "    if torch.cuda.is_available():\n",
        "        vram = torch.cuda.memory_allocated() / (1024**3)\n",
        "\n",
        "    # æ›´æ–°æ•°æ®\n",
        "    new_data = pd.DataFrame([\n",
        "        {\"Time\": now, \"Value\": ram, \"Type\": \"ç³»ç»Ÿå†…å­˜ (GB)\"},\n",
        "        {\"Time\": now, \"Value\": vram, \"Type\": \"æ˜¾å­˜ (GB)\"}\n",
        "    ])\n",
        "    perf_history = pd.concat([perf_history, new_data], ignore_index=True).tail(60)\n",
        "    return get_perf_figure(perf_history)\n",
        "\n",
        "# --- 2. ç¿»è¯‘æ¥å£ ---\n",
        "def gradio_interface(audio):\n",
        "    return translator.process(audio)\n",
        "\n",
        "# --- 3. UI ç•Œé¢ ---\n",
        "with gr.Blocks(title=\"ç²¤è¯­è½¬æ™®é€šè¯ AI\") as demo:\n",
        "    gr.Markdown(\"# ğŸ‡­ğŸ‡° ç²¤è¯­ -> ğŸ‡¨ğŸ‡³ æ™®é€šè¯ (æ€§èƒ½å®æ—¶ç›‘æ§ç‰ˆ)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_audio = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"è¯·è¯´ç²¤è¯­\")\n",
        "            btn = gr.Button(\"å¼€å§‹è½¬æ¢\", variant=\"primary\")\n",
        "\n",
        "            # æ€§èƒ½æŠ˜çº¿å›¾ - ç»™äºˆåˆå§‹å›¾è¡¨é˜²æ­¢åŠ è½½æ—¶ç©ºç™½\n",
        "            perf_plot = gr.Plot(value=get_perf_figure(perf_history), label=\"æ€§èƒ½è¶‹åŠ¿\")\n",
        "\n",
        "            # --- è°ƒè¯•ç‚¹ï¼šå…ˆæŠŠåˆ·æ–°æŒ‰é’®è®¾ä¸ºå¯è§ï¼Œå¦‚æœä½ ç‚¹å®ƒå›¾è¡¨åŠ¨äº†ï¼Œè¯´æ˜æ˜¯ JS æ²¡ç”Ÿæ•ˆ ---\n",
        "            hidden_btn = gr.Button(\"æ‰‹åŠ¨åˆ·æ–°ç›‘æ§ (æµ‹è¯•ç”¨)\", elem_id=\"refresh_trigger\", visible=True)\n",
        "\n",
        "        with gr.Column():\n",
        "            txt_cantonese = gr.Textbox(label=\"è¯†åˆ«ç»“æœ (ç²¤è¯­)\")\n",
        "            txt_mandarin = gr.Textbox(label=\"ç¿»è¯‘ç»“æœ (æ™®é€šè¯)\")\n",
        "            out_audio = gr.Audio(label=\"åˆæˆè¯­éŸ³ (æ™®é€šè¯)\", autoplay=True)\n",
        "\n",
        "    # ç»‘å®šç¿»è¯‘\n",
        "    btn.click(fn=gradio_interface, inputs=input_audio, outputs=[txt_cantonese, txt_mandarin, out_audio])\n",
        "\n",
        "    # ç»‘å®šç›‘æ§\n",
        "    hidden_btn.click(fn=update_monitor_plot, inputs=None, outputs=perf_plot)\n",
        "\n",
        "    # --- å¢å¼ºç‰ˆ JavaScript æ³¨å…¥ ---\n",
        "    gr.HTML(\"\"\"\n",
        "        <script>\n",
        "            function startAutoClicker() {\n",
        "                console.log(\"Monitoring script started...\");\n",
        "                setInterval(function() {\n",
        "                    // å°è¯•é€šè¿‡å¤šç§æ–¹å¼æŸ¥æ‰¾æŒ‰é’®\n",
        "                    var btn = document.getElementById('refresh_trigger') ||\n",
        "                              document.querySelector('#refresh_trigger') ||\n",
        "                              document.querySelector('button.secondary'); // å¤‡é€‰æ–¹æ¡ˆ\n",
        "\n",
        "                    if (btn) {\n",
        "                        // console.log(\"Clicking refresh...\"); // è°ƒè¯•ç”¨\n",
        "                        btn.click();\n",
        "                    }\n",
        "                }, 1000);\n",
        "            }\n",
        "            // å»¶è¿Ÿ 3 ç§’å¯åŠ¨ï¼Œç¡®ä¿ç•Œé¢å®Œå…¨åŠ è½½\n",
        "            setTimeout(startAutoClicker, 3000);\n",
        "        </script>\n",
        "    \"\"\")\n",
        "\n",
        "# å¯åŠ¨\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "7ZeUryQQ51Ll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "collapsed": true,
        "outputId": "475ebcad-7752-41e2-fe0e-7bcf1c6373ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://d1c0b7465c157ca290.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d1c0b7465c157ca290.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3221571911.py:45: FutureWarning:\n",
            "\n",
            "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æ­£åœ¨å¤„ç†: /tmp/gradio/13d7995ab913304e1a449f4def2ea82e7348354f256160c4fe137de3330d4ca8/audio.wav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
            "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
            "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n",
            "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
            "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
            "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨å¤„ç†: /tmp/gradio/c9121cdaff60f8fd52365f57e05a4a11556dcb773952ccdb196663e4515e22ea/audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your input_length: 335 is bigger than 0.9 * max_length: 200. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d1c0b7465c157ca290.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æ€§èƒ½å¯è§†åŒ–UIäº¤äº’ç•Œé¢ï¼ˆç¬¬ä¸‰ç‰ˆï¼Œä¿®æ­£æ—¶åŒºï¼‰\n",
        "import gradio as gr\n",
        "import psutil\n",
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import plotly.express as px\n",
        "\n",
        "# --- 1. ç›‘æ§æ•°æ®ä¸ç»˜å›¾é€»è¾‘ ---\n",
        "def get_perf_figure(history_df):\n",
        "    \"\"\"æ ¹æ®æ•°æ®ç”Ÿæˆ Plotly å›¾è¡¨\"\"\"\n",
        "    if history_df.empty:\n",
        "        fig = px.line(title=\"æ€§èƒ½ç›‘æ§å¯åŠ¨ä¸­...\")\n",
        "    else:\n",
        "        fig = px.line(\n",
        "            history_df, x=\"Time\", y=\"Value\", color=\"Type\",\n",
        "            title=\"å®æ—¶æ€§èƒ½ç›‘æ§ (ç§’çº§æ›´æ–° - åŒ—äº¬æ—¶é—´)\",\n",
        "            range_y=[0, 8],\n",
        "            template=\"plotly_white\"\n",
        "        )\n",
        "    fig.update_layout(height=300, margin=dict(l=10, r=10, t=40, b=10))\n",
        "    return fig\n",
        "\n",
        "# å­˜å‚¨å†å²æ•°æ®\n",
        "if 'perf_history' not in globals():\n",
        "    perf_history = pd.DataFrame(columns=[\"Time\", \"Value\", \"Type\"])\n",
        "\n",
        "def update_monitor_plot():\n",
        "    global perf_history\n",
        "\n",
        "    # ã€å…³é”®ä¿®æ”¹ã€‘ï¼šæ˜¾å¼æŒ‡å®šåŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰\n",
        "    beijing_tz = timezone(timedelta(hours=8))\n",
        "    now = datetime.now(beijing_tz).strftime(\"%H:%M:%S\")\n",
        "\n",
        "    # é‡‡é›†æ•°æ®\n",
        "    ram = psutil.virtual_memory().used / (1024**3)\n",
        "    vram = 0\n",
        "    if torch.cuda.is_available():\n",
        "        vram = torch.cuda.memory_allocated() / (1024**3)\n",
        "\n",
        "    # æ›´æ–°æ•°æ®\n",
        "    new_data = pd.DataFrame([\n",
        "        {\"Time\": now, \"Value\": ram, \"Type\": \"ç³»ç»Ÿå†…å­˜ (GB)\"},\n",
        "        {\"Time\": now, \"Value\": vram, \"Type\": \"æ˜¾å­˜ (GB)\"}\n",
        "    ])\n",
        "    perf_history = pd.concat([perf_history, new_data], ignore_index=True).tail(60)\n",
        "    return get_perf_figure(perf_history)\n",
        "\n",
        "# --- 2. ç¿»è¯‘æ¥å£ ---\n",
        "def gradio_interface(audio):\n",
        "    return translator.process(audio)\n",
        "\n",
        "# --- 3. UI ç•Œé¢ ---\n",
        "with gr.Blocks(title=\"ç²¤è¯­è½¬æ™®é€šè¯ AI\") as demo:\n",
        "    gr.Markdown(\"# ğŸ‡­ğŸ‡° ç²¤è¯­ -> ğŸ‡¨ğŸ‡³ æ™®é€šè¯ (æ€§èƒ½å®æ—¶ç›‘æ§ç‰ˆ)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_audio = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"è¯·è¯´ç²¤è¯­\")\n",
        "            btn = gr.Button(\"å¼€å§‹è½¬æ¢\", variant=\"primary\")\n",
        "            perf_plot = gr.Plot(value=get_perf_figure(perf_history), label=\"æ€§èƒ½è¶‹åŠ¿\")\n",
        "            hidden_btn = gr.Button(\"æ‰‹åŠ¨åˆ·æ–°ç›‘æ§\", elem_id=\"refresh_trigger\", visible=True)\n",
        "\n",
        "        with gr.Column():\n",
        "            txt_cantonese = gr.Textbox(label=\"è¯†åˆ«ç»“æœ (ç²¤è¯­)\")\n",
        "            txt_mandarin = gr.Textbox(label=\"ç¿»è¯‘ç»“æœ (æ™®é€šè¯)\")\n",
        "            out_audio = gr.Audio(label=\"åˆæˆè¯­éŸ³ (æ™®é€šè¯)\", autoplay=True)\n",
        "\n",
        "    # ç»‘å®šç¿»è¯‘\n",
        "    btn.click(fn=gradio_interface, inputs=input_audio, outputs=[txt_cantonese, txt_mandarin, out_audio])\n",
        "\n",
        "    # ç»‘å®šç›‘æ§\n",
        "    hidden_btn.click(fn=update_monitor_plot, inputs=None, outputs=perf_plot)\n",
        "\n",
        "    # JavaScript å®šæ—¶å™¨\n",
        "    gr.HTML(\"\"\"\n",
        "        <script>\n",
        "            function startAutoClicker() {\n",
        "                setInterval(function() {\n",
        "                    var btn = document.getElementById('refresh_trigger') ||\n",
        "                              document.querySelector('#refresh_trigger');\n",
        "                    if (btn) { btn.click(); }\n",
        "                }, 1000);\n",
        "            }\n",
        "            setTimeout(startAutoClicker, 3000);\n",
        "        </script>\n",
        "    \"\"\")\n",
        "\n",
        "# å¯åŠ¨\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "PW10-3gf35UF",
        "outputId": "dbac7794-e0af-4de3-f94c-755856d8e882"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://950d1b7083822651c5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://950d1b7083822651c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨å¤„ç†: /tmp/gradio/7a6be2ec584a65a19db63e4d0d38be1823409f4a93302b82ddca3eda40130475/audio.wav\n",
            "æ­£åœ¨å¤„ç†: /tmp/gradio/8af6a863366c7359157cc2f9f3b4e9676bbea589e8c384936ccc189aafe96837/audio.wav\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://950d1b7083822651c5.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}